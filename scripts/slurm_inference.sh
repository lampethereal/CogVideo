#!/bin/bash
# SLURM submission script for CogVideo inference (diffusers pipeline)
# Edit the VARIABLES section below to match your cluster and job needs.

#########################
# SLURM OPTIONS (change as needed)
#########################
#SBATCH --job-name=cogvideo_infer
#SBATCH --partition=gpu                 # partition/queue name
#SBATCH --gres=gpu:1                    # number of GPUs (per node)
#SBATCH --nodes=1                       # number of nodes
#SBATCH --ntasks-per-node=1             # number of tasks per node
#SBATCH --cpus-per-task=8               # CPUs per task (useful for data loading)
#SBATCH --mem=64G                       # memory per node (or use --mem-per-cpu)
#SBATCH --time=04:00:00                 # HH:MM:SS
#SBATCH --output=logs/inference-%j.out  # STDOUT
#SBATCH --error=logs/inference-%j.err   # STDERR
#SBATCH --mail-type=END,FAIL


#########################
# USER CONFIGURABLE VARIABLES
#########################
# ğŸ“ è¯¦ç»†å‚æ•°è¯´æ˜è¯·æŸ¥çœ‹: docs/INFERENCE_GUIDE_CN.md

# === æ¨¡å‹é…ç½® ===
MODEL_PATH="THUDM/CogVideoX1.5-5b"    # HF æ¨¡å‹ ID æˆ–æœ¬åœ°è·¯å¾„
                                       # t2v æ¨¡å‹: CogVideoX-2b / CogVideoX-5b / CogVideoX1.5-5b
                                       # i2v æ¨¡å‹: CogVideoX-5b-I2V / CogVideoX1.5-5b-I2V
LORA_PATH=""                          # (å¯é€‰) LoRA æƒé‡ç›®å½•è·¯å¾„

# === ç”Ÿæˆä»»åŠ¡é…ç½® ===
GENERATE_TYPE="t2v"                   # ä»»åŠ¡ç±»å‹ (å¿…é¡»ä¸æ¨¡å‹åŒ¹é…):
                                       # - t2v: æ–‡æœ¬ç”Ÿæˆè§†é¢‘ (éœ€è¦ t2v æ¨¡å‹)
                                       # - i2v: å›¾ç‰‡ç”Ÿæˆè§†é¢‘ (éœ€è¦ I2V æ¨¡å‹ + IMAGE_OR_VIDEO_PATH)
                                       # - v2v: è§†é¢‘ç”Ÿæˆè§†é¢‘ (ç”¨ t2v æ¨¡å‹ + IMAGE_OR_VIDEO_PATH)

PROMPT="A serene sunrise over a mountain lake, a superman ruin the earth"  # æ–‡æœ¬æç¤ºè¯

IMAGE_OR_VIDEO_PATH=""               # è¾“å…¥æ–‡ä»¶è·¯å¾„:
                                       # - i2v: å¿…é¡»æä¾›å›¾ç‰‡è·¯å¾„ (å¦‚ /path/to/image.jpg)
                                       # - v2v: å¿…é¡»æä¾›è§†é¢‘è·¯å¾„ (å¦‚ /path/to/video.mp4)
                                       # - t2v: ç•™ç©º

OUTPUT_PATH="./outputs/inference_${SLURM_JOB_ID}.mp4"  # è¾“å‡ºè§†é¢‘è·¯å¾„

# === ç”Ÿæˆå‚æ•° ===
NUM_FRAMES=81                        # ç”Ÿæˆå¸§æ•°:
                                       # - CogVideoX 1.0 (2b/5b): 49 å¸§ (6ç§’@8fps)
                                       # - CogVideoX 1.5: 81 å¸§ (5ç§’@16fps) æˆ– 161 å¸§ (10ç§’@16fps)

FPS=16                               # è§†é¢‘å¸§ç‡:
                                       # - CogVideoX 1.0: 8 fps
                                       # - CogVideoX 1.5: 16 fps

NUM_STEPS=50                         # æ¨ç†æ­¥æ•° (30-100, è¶Šå¤§è´¨é‡è¶Šå¥½ä½†è¶Šæ…¢)
GUIDANCE_SCALE=6.0                   # CFG å¼•å¯¼å¼ºåº¦ (5.0-10.0, æ§åˆ¶ä¸ prompt çš„è´´åˆåº¦)

DTYPE="bfloat16"                     # è®¡ç®—ç²¾åº¦:
                                       # - float16: æ¨èç”¨äº CogVideoX-2b
                                       # - bfloat16: æ¨èç”¨äº CogVideoX-5b å’Œ 1.5 ç³»åˆ—

# (Optional) path to python environment activation script
CONDA_ACTIVATE_CMD="source activate CogVideoX" # or use your environment activation command

#########################
# Prepare environment
#########################
set -euo pipefail
mkdir -p logs

# Activate environment (edit to your cluster's env setup)
if [ -n "${CONDA_ACTIVATE_CMD}" ]; then
  eval "${CONDA_ACTIVATE_CMD}"
fi

# Show some info
echo "Job id: ${SLURM_JOB_ID}"
echo "Running on nodes: $(scontrol show hostnames $SLURM_NODELIST)"
echo "CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"

#########################
# Inference command
#########################
# We use the diffusers CLI demo. Adjust flags as necessary.
INFER_CMD=(python -u inference/cli_demo.py
  --prompt "${PROMPT}"
  --model_path "${MODEL_PATH}"
  --num_frames ${NUM_FRAMES}
  --num_inference_steps ${NUM_STEPS}
  --output_path "${OUTPUT_PATH}"
  --guidance_scale ${GUIDANCE_SCALE}
  --generate_type "${GENERATE_TYPE}"
  --dtype "${DTYPE}"
  --fps ${FPS}
)

# Add optional image/video or LoRA args
if [ -n "${IMAGE_OR_VIDEO_PATH}" ]; then
  INFER_CMD+=(--image_or_video_path "${IMAGE_OR_VIDEO_PATH}")
fi
if [ -n "${LORA_PATH}" ]; then
  INFER_CMD+=(--lora_path "${LORA_PATH}")
fi

# Print and run
echo "Running inference command: ${INFER_CMD[@]}"
"${INFER_CMD[@]}"

echo "Inference finished. Output: ${OUTPUT_PATH}"
